{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+-------------------+-----------+-----------+-----------+-----------+----------------+------------------+\n",
      "|SNo|Name|Symbol|               Date|       High|        Low|       Open|      Close|          Volume|         Marketcap|\n",
      "+---+----+------+-------------------+-----------+-----------+-----------+-----------+----------------+------------------+\n",
      "|  1|Aave|  AAVE|2020-10-05 23:59:59|55.11235847|49.78789992|52.67503496|53.21924296|             0.0| 89128128.86084658|\n",
      "|  2|Aave|  AAVE|2020-10-06 23:59:59|53.40227002|40.73457791|53.29196931|42.40159861|  583091.4597628| 71011441.25451232|\n",
      "|  3|Aave|  AAVE|2020-10-07 23:59:59|42.40831364|35.97068975|42.39994711|40.08397561| 682834.18632335| 67130036.89981823|\n",
      "|  4|Aave|  AAVE|2020-10-08 23:59:59|44.90251114|36.69605677|39.88526234|43.76446306|1658816.92260445|220265142.10956782|\n",
      "|  5|Aave|  AAVE|2020-10-09 23:59:59|47.56953274| 43.2917758|43.76446306|46.81774415|  815537.6607835|235632208.16269898|\n",
      "+---+----+------+-------------------+-----------+-----------+-----------+-----------+----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining them all into a single csv file\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "os.chdir(\"crypto_data\")\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ]).reset_index()\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"crypto_data.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the combined data into spark object\n",
    "df = sqlContext.read.csv('crypto_data/crypto_data.csv',header=True)\n",
    "\n",
    "# Selecting the data within a time range\n",
    "from datetime import datetime\n",
    "def get_date_time_obj(date_time_str):\n",
    "    date = datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S')\n",
    "    return date\n",
    "min_date = get_date_time_obj('2018-07-01 00:00:00')\n",
    "max_date = get_date_time_obj('2021-07-01 23:59:59')\n",
    "\n",
    "\n",
    "# Use filterbyvalues to select those files in the range\n",
    "filtered_rdd = df.rdd.filter(lambda x: get_date_time_obj(x[4])>=min_date and get_date_time_obj(x[4])<=max_date)\n",
    "#print(filtered_dff.count())\n",
    "\n",
    "# Map to name-marketcap key-value pair\n",
    "market_cap_rdd = filtered_rdd.map(lambda x: (x[2],float(x[10])))\n",
    "\n",
    "# Selecting the top 10 cryptos by market value\n",
    "top10_by_avg_market_cap = market_cap_rdd.mapValues(lambda x: (x,1)) \\\n",
    "    .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1])) \\\n",
    "    .mapValues(lambda y: y[0]/y[1]).sortBy(lambda x: (-x[1])).take(10)\n",
    "\n",
    "top10_list = [x[0] for x in top10_by_avg_market_cap]\n",
    "top10_list\n",
    "\n",
    "# Filtering out only the top 10 cryptos\n",
    "selected_crypto_rdd = filtered_rdd.filter(lambda x: x[2] in top10_list)\n",
    "#selected_crypto_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2020-08-21 23:59:59', 9),\n",
       " ('2020-08-25 23:59:59', 9),\n",
       " ('2020-08-26 23:59:59', 9),\n",
       " ('2020-08-31 23:59:59', 9),\n",
       " ('2020-09-01 23:59:59', 9)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further EDA\n",
    "# Checking to see if data is present for all 1097 dates from 1st Jul 2018 to 1st Jul 2021\n",
    "# counting by the number of entries for each date\n",
    "value_count_for_each_date = selected_crypto_rdd.map(lambda x: (x[4],1)) \\\n",
    "                    .reduceByKey(lambda a,b: a+b).collect()\n",
    "print(len(value_count_for_each_date))\n",
    "# there are 1097 dates present. Voila!\n",
    "# (can consider taking only those which are also present in the stock market data)\n",
    "# a peak into the counts\n",
    "value_count_for_each_date[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Binance Coin', 1097)\n",
      "('Bitcoin', 1097)\n",
      "('Ethereum', 1097)\n",
      "('Dogecoin', 1097)\n",
      "('Cardano', 1097)\n",
      "('Tether', 1097)\n",
      "('Litecoin', 1097)\n",
      "('XRP', 1097)\n",
      "('Polkadot', 315)\n",
      "('Uniswap', 287)\n"
     ]
    }
   ],
   "source": [
    "# can see that some cryptos don't have info for every date\n",
    "# checking number of entries for each crypto\n",
    "value_count = selected_crypto_rdd.map(lambda x: (x[2],1)) \\\n",
    "                    .reduceByKey(lambda a,b: a+b).sortBy(lambda x: (-x[1])).collect()\n",
    "for i in value_count:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some values are missing for the last two currencies but cannot ignore them as they are important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9378\n",
      "9378\n"
     ]
    }
   ],
   "source": [
    "# checking for any other missing values\n",
    "print(selected_crypto_rdd.count())\n",
    "df = sqlContext.createDataFrame(selected_crypto_rdd)\n",
    "print(df.na.drop().rdd.count())\n",
    "# counts before and after removing missing values is the same\n",
    "# Hence no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index        0\n",
       "SNo          0\n",
       "Name         0\n",
       "Symbol       0\n",
       "Date         0\n",
       "High         0\n",
       "Low          0\n",
       "Open         0\n",
       "Close        0\n",
       "Volume       0\n",
       "Marketcap    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for any missing values with pandas as well\n",
    "import pandas as pd\n",
    "df_pd = pd.read_csv('crypto_data.csv')\n",
    "df_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harry/Desktop/Project/crypto_data\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the file\n",
    "df.write.csv('crypto10_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat ../crypto10_final/part* > crypto10_final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harry/Desktop/Project/crypto_data\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
